{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./images/logo.png\" alt=\"drawing\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
    "\n",
    "# ML through Application \n",
    "## Module 3, Lab 4, Notebook 1: Bias Mitigation during Preprocessing\n",
    "\n",
    "This notebook shows how to implement reweighting as a bias mitigation method to use before a model is trained.\n",
    "\n",
    "You will learn how to implement a bias mitigation step by using reweighting (manually and using a fairness Python library). The Python library you will use calls this process \"reweighing\" instead of \"reweighting\" (but uses the same technique as described in the course).\n",
    "\n",
    "__Dataset:__ \n",
    "You will use [Folktables](https://github.com/zykls/folktables) to download a dataset for this lab. Folktables provides an API to download data from the American Community Survey (ACS) Public Use Microdata Sample (PUMS) files, which the U.S. Census Bureau manages. The data itself is governed by the terms of use that are provided by the Census Bureau. For more information, see the [Terms of Service](https://www.census.gov/data/developers/about/terms-of-service.html). \n",
    "\n",
    "You will filter the ACS PUMS data sample to include only individuals who are above the age of 16, reported usual working hours of at least 1 hour per week in the past year, and have an income of at least \\\\$100. \n",
    "The threshold of \\\\$50,000 was chosen so that this dataset can serve as a comparable replacement to the [UCI Adult dataset](https://archive.ics.uci.edu/ml/datasets/adult), but the income threshold can be changed easily to define new prediction tasks. Historically, the [UCI Adult dataset](https://archive.ics.uci.edu/ml/datasets/adult) served as the basis for the development and comparison of many algorithmic fairness interventions but has limited documentation, outdated feature encodings, and only contains a binary target label which can lead to misrepresentations for certain subpopulations. In order to compare your results with scientific findings that utilize the UCI Adult dataset, and to have greater control and flexibility in setting up the problem, you will utilize the ACS PUMS data with the filters and thresholds described above.\n",
    "\n",
    "__ML problem:__ \n",
    "The goal is to predict whether an individual's income is above \\\\$50,000. \n",
    "This is a binary prediction task that can enable organizations and businesses to target their marketing efforts more effectively. Alternatively, governments could leverage these predictions to design better social welfare programs and allocate resources efficiently. Keep these kinds of problems in mind, when working through the notebook.\n",
    "\n",
    "Reference: Dua, D. and Graff, C. (2019). UCI Machine Learning Repository. http://archive.ics.uci.edu/ml. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "----\n",
    "\n",
    "You will be presented with activities throughout the notebook: <br/>\n",
    "\n",
    "|<img style=\"float: center;\" src=\"./images/activity.png\" alt=\"Activity\" width=\"125\"/>| \n",
    "| --- | \n",
    "|<p style=\"text-align:center;\"> No coding is needed for an activity. You try to understand a concept, <br/>answer questions, or run a code cell.</p>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "- [Read in the dataset](#Read-in-the-dataset)\n",
    "- [Data processing](#Data-processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Before loading in the dataset, make sure to install and import all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use pip to install libraries\n",
    "!pip install --no-deps -U -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Import the libraries needed for the notebook\n",
    "\n",
    "# Reshaping/basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "# Import questions\n",
    "from MLUMLA_EN_M3_Lab4_quiz_questions import *\n",
    "\n",
    "# Fairness libraries\n",
    "from folktables.acs import *\n",
    "from folktables.folktables import *\n",
    "from folktables.load_acs import *\n",
    "from aif360.datasets import BinaryLabelDataset, Dataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "# Jupyter(lab) libraries\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Read in the dataset\n",
    "\n",
    "Import the data from Folktables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "income_features = [\n",
    "    \"AGEP\",  # age individual\n",
    "    \"COW\",  # class of worker\n",
    "    \"SCHL\",  # educational attainment\n",
    "    \"MAR\",  # marital status\n",
    "    \"OCCP\",  # occupation\n",
    "    \"POBP\",  # place of birth\n",
    "    \"RELP\",  # relationship\n",
    "    \"WKHP\",  # hours worked per week past 12 months\n",
    "    \"SEX\",  # sex\n",
    "    \"RAC1P\",  # recorded detailed race code\n",
    "    \"PWGTP\",  # persons weight\n",
    "    \"GCL\",  # grandparents living with grandchildren\n",
    "]\n",
    "\n",
    "# Define the prediction problem and features\n",
    "ACSIncome = folktables.BasicProblem(\n",
    "    features=income_features,\n",
    "    target=\"PINCP\",  # total persons income\n",
    "    target_transform=lambda x: x > 50000,\n",
    "    group=\"RAC1P\",\n",
    "    preprocess=adult_filter,  # applies the following conditions; ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "    postprocess=lambda x: x,  # applies post processing, for example: fill all NAs\n",
    ")\n",
    "\n",
    "# Initialize year, duration (\"1-Year\" or \"5-Year\") and granularity (household or person)\n",
    "data_source = ACSDataSource(survey_year=\"2018\", horizon=\"1-Year\", survey=\"person\")\n",
    "# Specify region (here: California) and load data\n",
    "ca_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "# Apply transformation as per problem statement above\n",
    "ca_features, ca_labels, ca_group = ACSIncome.df_to_numpy(ca_data)\n",
    "\n",
    "# Convert NumPy array to DataFrame\n",
    "df = pd.DataFrame(\n",
    "    np.concatenate((ca_features, ca_labels.reshape(-1, 1)), axis=1),\n",
    "    columns=income_features + [\">50k\"],\n",
    ")\n",
    "\n",
    "# For further modeling, use only two groups\n",
    "df = df[df[\"RAC1P\"].isin([6, 8])].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data processing\n",
    "\n",
    "Split the categorical and numerical features to keep them separate. Start by creating a list for each feature type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    \"COW\",\n",
    "    \"SCHL\",\n",
    "    \"MAR\",\n",
    "    \"OCCP\",\n",
    "    \"POBP\",\n",
    "    \"RELP\",\n",
    "    \"SEX\",\n",
    "    \"RAC1P\",\n",
    "]\n",
    "\n",
    "numerical_features = [\"AGEP\", \"WKHP\", \"PWGTP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cast categorical features to `category`\n",
    "df[categorical_features] = df[categorical_features].astype(\"object\")\n",
    "\n",
    "# Cast numerical features to `int`\n",
    "df[numerical_features] = df[numerical_features].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can now separate model features from the model target to explore them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_target = \">50k\"\n",
    "model_features = categorical_features + numerical_features\n",
    "\n",
    "print(\"Model features: \", model_features)\n",
    "print(\"Model target: \", model_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check that the target is not accidentally part of the features\n",
    "model_target in model_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good. You made sure that the target is not in the feature list. If the output of the previous cell is `True`, you need to remove the target by calling `model_features.remove(model_target)`.\n",
    "\n",
    "Next, you will look for missing values.\n",
    "\n",
    "### Check for missing values\n",
    "The quickest way to check for missing values is to use `.isna().sum()`. This will provide a count of missing values.\n",
    "\n",
    "You can also see the count of missing values with `.info()` because the function provides a count of non-null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a threshold-based way to drop columns with too many missing values. You want to drop all columns where more than 20 percent of the data is missing. (Note that this is an example threshold that doesn't apply universally.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.loc[:, df.isnull().mean() < 0.2]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformation\n",
    "\n",
    "Now that you dropped the missing values, you want to implement reweighting of the features before they are passed to the model. You will use AIF360 for this and initialize the `Reweighing` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Declare the attribute values of the privileged and unprivileged groups\n",
    "priv_group = [{\"RAC1P\": 6}]\n",
    "unpriv_group = [{\"RAC1P\": 8}]\n",
    "\n",
    "rw = Reweighing(unprivileged_groups=unpriv_group, privileged_groups=priv_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dataset construct for AIF360\n",
    "binaryLabelDataset = BinaryLabelDataset(\n",
    "    df=df,\n",
    "    label_names=[model_target],\n",
    "    protected_attribute_names=[\"RAC1P\"],\n",
    "    favorable_label=1.0,\n",
    "    unfavorable_label=0.0,\n",
    ")\n",
    "\n",
    "binaryLabelDataset_transform = rw.fit_transform(binaryLabelDataset)\n",
    "weights = pd.DataFrame(\n",
    "    {\n",
    "        \"weights\": binaryLabelDataset_transform.convert_to_dataframe()[1][\n",
    "            \"instance_weights\"\n",
    "        ]\n",
    "    }\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look at the transformed dataset\n",
    "df_transformed = binaryLabelDataset_transform.convert_to_dataframe()[0]\n",
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare to the original dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that no differences exist between the datasets. You didn't change the data directly but got a list of weights that you can use instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you prefer not to use AIF360, you can code a custom reweigh function. An example is provided in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reweighing(data, label, sensitive_attr, return_list=True):\n",
    "    \"Function that calculates reweighting factors based on given model target and sensitive attribute.\" \"\"\n",
    "    # Initialize dict for the different classes of labels\n",
    "    label_dict = dict()\n",
    "    try:\n",
    "        # Loop through different labels\n",
    "        for outcome in data[label].unique():\n",
    "            # Initialize empty dict to store weight values\n",
    "            weight_map = dict()\n",
    "            # Loop through different sensitive attributes\n",
    "            for val in data[sensitive_attr].unique():\n",
    "                # Count per outcome type, per sensitive attribute class\n",
    "                nom = (\n",
    "                    len(data[data[sensitive_attr] == val])\n",
    "                    / len(data)\n",
    "                    * len(data[data[label] == outcome])\n",
    "                    / len(data)\n",
    "                )\n",
    "                denom = len(\n",
    "                    data[(data[sensitive_attr] == val) & (data[label] == outcome)]\n",
    "                ) / len(data)\n",
    "                # Calculate fraction to obtain weight\n",
    "                weight_map[val] = round(nom / denom, 2)\n",
    "            # Store output in list\n",
    "            label_dict[outcome] = weight_map\n",
    "        # Map values back to correct data points\n",
    "        data[\"weights\"] = list(\n",
    "            map(lambda x, y: label_dict[y][x], data[sensitive_attr], data[label])\n",
    "        )\n",
    "        # Enable to return a list of the weights\n",
    "        if return_list == True:\n",
    "            return data[\"weights\"].to_list()\n",
    "        else:\n",
    "            return label_dict\n",
    "    # Catch error\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print(\"Dataframe might have no entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use a custom function to calculate reweighting\n",
    "weight_manual = pd.DataFrame({\"weights\": reweighing(df, model_target, \"RAC1P\", True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare outputs\n",
    "Now, check whether the weights that you calculated manually with the custom function agree with the output from AIF360."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight_manual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the outputs are the same between the AIF360 library and the custom function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\"> \n",
    "    <h3><i>Try it yourself!</i></h3>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"./images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">You know that individuals can experience multiple and different sensitive attributes. How would you calculate the weighting factors, assuming that SEX is the sensitive attribute?</p>\n",
    "    <p style=\" text-align: center; margin: auto;\">To answer the question, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell for a knowledge check question\n",
    "question_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
    "    <h3><i>Try it Yourself!</i></h3>\n",
    "    <br>\n",
    "    <p style=\"text-align:center;margin:auto;\"><img src=\"./images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
    "    <p style=\" text-align: center; margin: auto;\">In a new cell, run the code from the correct answer to the previous question. Are the weights when using SEX as sensitive attribue the same as the weights when using RAC1P? You can create a new code cell and run the <code>reweighing</code> function for RAC1P and for SEX to check whether the values are the same.</p>\n",
    "        <p style=\" text-align: center; margin: auto;\">To answer the question, run the following cell.</p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell for a knowledge check question\n",
    "question_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n",
    "Different combinations of attributes will yield different weights. You can implement reweighing by using existing Python libraries or by using custom functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To finish this lab, continue to notebook 2.**"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
